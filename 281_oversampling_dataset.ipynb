{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from skimage.transform import rotate\n",
    "from skimage.feature import graycomatrix, graycoprops, hog\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.color import rgb2gray\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hair(image, size=(600, 450)):\n",
    "    image = cv2.resize(image, size)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))\n",
    "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
    "    _, mask = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n",
    "    cleaned = cv2.inpaint(image, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    \"\"\"Applies a random selection of augmentations to an image.\"\"\"\n",
    "    if random.choice([True, False]):\n",
    "        image = cv2.flip(image, 1)  # Horizontal Flip\n",
    "    if random.choice([True, False]):\n",
    "        image = cv2.flip(image, 0)  # Vertical Flip\n",
    "\n",
    "    # Random rotation\n",
    "    angle = random.uniform(-15, 15)\n",
    "    image = rotate(image, angle, resize=False, preserve_range=True, mode='reflect')\n",
    "    image = image.astype(np.uint8)\n",
    "\n",
    "    # Brightness adjustment\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    value = random.uniform(0.8, 1.2)\n",
    "    v = cv2.multiply(v, np.array([value]))\n",
    "    v = np.clip(v, 0, 255).astype(np.uint8)\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    image = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    return image\n",
    "\n",
    "def extract_features_from_array(image_rgb):\n",
    "    \"\"\"Extracts features from an in-memory RGB image array.\"\"\"\n",
    "    # Preprocessing\n",
    "    image = cv2.resize(image_rgb, (224, 224))\n",
    "    image = remove_hair(image)\n",
    "    image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    features = []\n",
    "\n",
    "    hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, [8, 8, 8], [0, 180, 0, 256, 0, 256])\n",
    "    features.extend(cv2.normalize(hist, hist).flatten())\n",
    "\n",
    "    glcm = graycomatrix(gray, [1], [0, np.pi/4, np.pi/2], symmetric=True, normed=True)\n",
    "    for prop in ['contrast', 'correlation', 'energy', 'homogeneity']:\n",
    "        features.append(graycoprops(glcm, prop)[0].mean())\n",
    "\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    features.append(np.sum(edges > 0) / (224 * 224))\n",
    "\n",
    "    hog_feat, _ = hog(rgb2gray(image), pixels_per_cell=(16, 16),\n",
    "                      cells_per_block=(2, 2), visualize=True, feature_vector=True)\n",
    "    features.extend(hog_feat[:100])\n",
    "\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    props = regionprops(label(binary))\n",
    "    if props:\n",
    "        largest = max(props, key=lambda x: x.area)\n",
    "        area, perimeter = largest.area, largest.perimeter\n",
    "        circularity = (4 * np.pi * area) / (perimeter**2 + 1e-5)\n",
    "        features.extend([area / (224*224), perimeter / (224*4), circularity])\n",
    "    else:\n",
    "        features.extend([0, 0, 0])\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 6970\n",
      "Validation set size: 1494\n",
      "Test set size: 1494\n",
      "\n",
      "--- Processing and Oversampling Training Set ---\n",
      "Processing class: bkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original bkl: 100%|██████████| 762/762 [02:01<00:00,  6.29it/s]\n",
      "Augmenting bkl:   0%|          | 0/3900 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'COLOR_RGB_HSV'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m original_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(random_path)\n\u001b[1;32m     52\u001b[0m original_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(original_image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m---> 53\u001b[0m augmented_image \u001b[38;5;241m=\u001b[39m \u001b[43maugment_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m features \u001b[38;5;241m=\u001b[39m extract_features_from_array(augmented_image)\n\u001b[1;32m     55\u001b[0m X_train\u001b[38;5;241m.\u001b[39mappend(features)\n",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m, in \u001b[0;36maugment_image\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     11\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Brightness adjustment\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m hsv \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_RGB_HSV\u001b[49m)\n\u001b[1;32m     15\u001b[0m h, s, v \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39msplit(hsv)\n\u001b[1;32m     16\u001b[0m value \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1.2\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'COLOR_RGB_HSV'"
     ]
    }
   ],
   "source": [
    "base_dir = '/Users/conorhuh/Desktop/Berkeley/281/fp/skin-cancer-mnist-ham10000/' \n",
    "df = pd.read_csv(os.path.join(base_dir, 'HAM10000_metadata.csv'))\n",
    "\n",
    "image_paths = {os.path.splitext(os.path.basename(x))[0]: os.path.join(base_dir, 'ham10000_images_part_1', x)\n",
    "               for x in os.listdir(os.path.join(base_dir, 'ham10000_images_part_1'))}\n",
    "image_paths.update({os.path.splitext(os.path.basename(x))[0]: os.path.join(base_dir, 'ham10000_images_part_2', x)\n",
    "                    for x in os.listdir(os.path.join(base_dir, 'ham10000_images_part_2'))})\n",
    "df['path'] = df['image_id'].map(image_paths.get)\n",
    "df.dropna(inplace=True) \n",
    "\n",
    "# 70% train, 30% temp (for val/test)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.30, stratify=df['dx'], random_state=42)\n",
    "\n",
    "# Split the 30% temp set into 15% validation and 15% test\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.50, stratify=temp_df['dx'], random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "\n",
    "\n",
    "# --- 2. Oversample the TRAINING Set ---\n",
    "print(\"\\n--- Processing and Oversampling Training Set ---\")\n",
    "# Get the new majority class count from the training set\n",
    "train_majority_count = train_df['dx'].value_counts().max()\n",
    "# Find the name of the majority class\n",
    "majority_class_name = train_df['dx'].value_counts().idxmax()\n",
    "\n",
    "target_counts = {dx_class: train_majority_count for dx_class in df['dx'].unique()}\n",
    "\n",
    "X_train, y_train = [], []\n",
    "\n",
    "for dx_class, target_count in target_counts.items():\n",
    "    print(f\"Processing class: {dx_class}\")\n",
    "    class_df = train_df[train_df['dx'] == dx_class]\n",
    "    original_images = class_df['path'].tolist()\n",
    "    current_count = len(original_images)\n",
    "\n",
    "    if dx_class == majority_class_name:\n",
    "        # For the MAJORITY class, replace each original image with an augmented version\n",
    "        # This teaches the model transformation invariance for this class.\n",
    "        for image_path in tqdm(original_images, desc=f\"Augmenting majority {dx_class}\"):\n",
    "            original_image = cv2.imread(image_path)\n",
    "            original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "            augmented_image = augment_image(original_image) # Augment every image\n",
    "            features = extract_features_from_array(augmented_image)\n",
    "            X_train.append(features)\n",
    "            y_train.append(dx_class)\n",
    "    else:\n",
    "        # For MINORITY classes, add the originals and then augment to reach the target count\n",
    "        # 1. Add original images\n",
    "        for image_path in tqdm(original_images, desc=f\"Original {dx_class}\"):\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            features = extract_features_from_array(image)\n",
    "            X_train.append(features)\n",
    "            y_train.append(dx_class)\n",
    "\n",
    "        # 2. Augment to fill the gap\n",
    "        num_to_generate = target_count - current_count\n",
    "        if num_to_generate > 0:\n",
    "            for i in tqdm(range(num_to_generate), desc=f\"Augmenting minority {dx_class}\"):\n",
    "                random_path = random.choice(original_images)\n",
    "                original_image = cv2.imread(random_path)\n",
    "                original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "                augmented_image = augment_image(original_image)\n",
    "                features = extract_features_from_array(augmented_image)\n",
    "                X_train.append(features)\n",
    "                y_train.append(dx_class)\n",
    "\n",
    "\n",
    "# --- 3. Process the VALIDATION and TEST Sets (NO Augmentation) ---\n",
    "def process_set(dataframe, set_name):\n",
    "    \"\"\"Helper function to extract features for a given dataframe.\"\"\"\n",
    "    print(f\"\\n--- Processing {set_name} Set ---\")\n",
    "    X, y = [], []\n",
    "    for index, row in tqdm(dataframe.iterrows(), total=len(dataframe), desc=f\"Processing {set_name}\"):\n",
    "        image = cv2.imread(row['path'])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        features = extract_features_from_array(image)\n",
    "        X.append(features)\n",
    "        y.append(row['dx'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_val, y_val = process_set(val_df, \"Validation\")\n",
    "X_test, y_test = process_set(test_df, \"Test\")\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "np.savez('skin_cancer_datasets.npz',\n",
    "         X_train=X_train, y_train=y_train,\n",
    "         X_val=X_val, y_val=y_val,\n",
    "         X_test=X_test, y_test=y_test)\n",
    "\n",
    "print(\"\\nAll datasets saved to 'skin_cancer_datasets.npz'\")\n",
    "print(f\"Training set shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Validation set shape: X={X_val.shape}, y={y_val.shape}\")\n",
    "print(f\"Test set shape: X={X_test.shape}, y={y_test.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "281",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
